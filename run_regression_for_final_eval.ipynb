{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Notebook for final model building evaluation\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, scale, normalize\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_predict,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    KFold\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    make_scorer,\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from tc_data import TopCoder\n",
    "from final_model_selection import (\n",
    "    kfold_predict_validate_gradient_boosting,\n",
    "    kfold_predict_validate_neural_network\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "pd.set_option('display.max_rows', 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data object\n",
    "\n",
    "`TopCoder` class contain the pre-processed data retrieved from data base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tc = TopCoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Gradient Boosting against NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_param_dct = {\n",
    "    'avg_score': {'gb': {}, 'nn': {}},\n",
    "    'number_of_registration': {'gb': dict(tol=4), 'nn': dict(es_min_delta=4)},\n",
    "    'sub_reg_ratio': {'gb': dict(loss='lad', tol=0.001, n_iter_no_change=10), 'nn': dict(es_min_delta=0.001)},\n",
    "    'total_prize': {'gb': dict(loss='ls', tol=10, n_iter_no_change=5), 'nn': dict(es_min_delta=10)}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "for target, param_dct in hyper_param_dct.items():\n",
    "    X, y = tc.build_final_dataset(target)\n",
    "    gb_y_pred, gb_cv_eval_df, gb_manual_score, gb_cv_fi = kfold_predict_validate_gradient_boosting(X, y, **param_dct['gb'])\n",
    "    nn_y_pred, nn_cv_eval_df, nn_manual_score = kfold_predict_validate_neural_network(X, y, **param_dct['nn'])\n",
    "    \n",
    "    res[target] = dict(\n",
    "        y=y,\n",
    "        gb_y_pred=gb_y_pred,\n",
    "        nn_y_pred=nn_y_pred,\n",
    "        gb_cv_mean=gb_cv_eval_df.mean(),\n",
    "        nn_cv_mean=nn_cv_eval_df.mean(),\n",
    "        gb_manual=pd.Series(gb_manual_score),\n",
    "        nn_manual=pd.Series(nn_manual_score)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_idx_dct = defaultdict(dict)\n",
    "algo_name = {\n",
    "    'gb': 'Gradient Boosting',\n",
    "    'nn': 'Neural Network',\n",
    "}\n",
    "result_name = {\n",
    "    'cv_mean': 'CV Mean',\n",
    "    'manual': 'Full Set',\n",
    "}\n",
    "\n",
    "for target in res:\n",
    "    for algo in ('gb', 'nn'):\n",
    "        for result in ('cv_mean', 'manual'):\n",
    "            for metric, score in res[target][f'{algo}_{result}'].iteritems():\n",
    "                multi_idx_dct[(metric, result_name[result])][(target, algo_name[algo])] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_metrics = pd.DataFrame.from_dict(multi_idx_dct, orient='index').sort_index()\n",
    "prediction_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "endpoint = [100, 300, 1, 2500]\n",
    "\n",
    "with sns.axes_style('darkgrid'):\n",
    "    fig, axes = plt.subplots(4, 2, figsize=(8, 16), dpi=200)\n",
    "    for i, (target, predict_res) in enumerate(res.items()):\n",
    "        for j, (algo, title) in enumerate(algo_name.items()):\n",
    "            ax = axes[i, j]\n",
    "            sns.scatterplot(\n",
    "                x=predict_res[f'{algo}_y_pred'],\n",
    "                y=predict_res['y'],\n",
    "                s=20,\n",
    "                alpha=0.5,\n",
    "                linewidth=0.1,\n",
    "                ax=ax,\n",
    "            )\n",
    "            sns.lineplot(\n",
    "                x=[0, endpoint[i]],\n",
    "                y=[0, endpoint[i]],\n",
    "                color='red',\n",
    "                alpha=0.75,\n",
    "                ax=ax,\n",
    "            )\n",
    "            ax.set_title(f'{target.capitalize()} - {title}')\n",
    "            ax.set_xlabel('Prediction')\n",
    "            ax.set_ylabel('Ground Truth')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "#     fig.savefig('./result/img/pred_against_truth.png', dpi='figure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the feature importance of Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_param_dct = {k: v['gb'] for k, v in hyper_param_dct.items()}\n",
    "del gb_param_dct['total_prize']\n",
    "gb_param_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_res = {}\n",
    "for target, param in gb_param_dct.items():\n",
    "    X, y = tc.build_final_dataset(target)\n",
    "    y_pred, cv_eval_df, manual_score, cv_feature_importance = kfold_predict_validate_gradient_boosting(X, y, **param)\n",
    "\n",
    "    gb_res[target] = dict(\n",
    "        y=y,\n",
    "        y_pred=y_pred,\n",
    "        cv_mean=cv_eval_df.mean(),\n",
    "        manual=pd.Series(manual_score),\n",
    "        fea_importance = cv_feature_importance.mean()\n",
    "    )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midx_dct = defaultdict(dict)\n",
    "for target, res_dct in gb_res.items():\n",
    "    for result in 'cv_mean', 'manual':\n",
    "        for metric, score in res_dct[result].items():\n",
    "            midx_dct[target][(metric, result)] = score\n",
    "        \n",
    "res_df = pd.DataFrame.from_dict(midx_dct).sort_index()\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_json('result/final_models/extened_features_gradient_boosting_result.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_imp_dct = {\n",
    "    target: res_dct['fea_importance'] for target, res_dct in gb_res.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = [f'#{color}' for color in'641220-6e1423-85182a-a11d33-a71e34-b21e35-bd1f36-c71f37-da1e37-e01e37'.split('-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(8, 8), dpi=200, sharex=True)\n",
    "    for i, (target, feature_imp) in enumerate(fea_imp_dct.items()):\n",
    "        ax = axes[i]\n",
    "\n",
    "        sns.barplot(\n",
    "            x=feature_imp.sort_values(ascending=False).head(10),\n",
    "            y=feature_imp.sort_values(ascending=False).head(10).index,\n",
    "            ax=ax,\n",
    "            palette=palette[::-1]\n",
    "        )\n",
    "        ax.set_title('{} - Feature Importance'.format(' '.join([w.capitalize() for w in target.split('_')])))\n",
    "        ax.set_xlim(0, 1)\n",
    "        \n",
    "        for p in ax.patches:\n",
    "            x = p.get_width() + 0.01\n",
    "            y = p.get_y() + 0.5 * p.get_height() + 0.002\n",
    "            importance = round(p.get_width(), 3)\n",
    "            ax.text(x, y, importance, va='center', fontdict={'fontsize': 8})\n",
    "            \n",
    "    fig.tight_layout()\n",
    "#     fig.savefig('result/img/gradient_boosting_feature_importance.png', dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (BERT TCPM)",
   "language": "python",
   "name": "bert_tcpm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
