{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Just a work bench\"\"\"\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, scale, StandardScaler, Normalizer\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    cross_val_predict, \n",
    "    cross_validate, \n",
    "    learning_curve,\n",
    "    validation_curve,\n",
    "    KFold, \n",
    "    train_test_split,\n",
    "    GridSearchCV\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, \n",
    "    mean_absolute_error,\n",
    "    median_absolute_error,\n",
    "    mean_squared_error, \n",
    "    r2_score, \n",
    "    explained_variance_score\n",
    ")\n",
    "from sklearn.manifold import TSNE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from smogn import smoter\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "from tc_data import TopCoder\n",
    "from run_nn_classification import build_dataset\n",
    "from model_tcpm_distilbert import (\n",
    "    TCPMDistilBertClassification,\n",
    "    build_tcpm_model_distilbert_classification,\n",
    "    build_tcpm_model_distilbert_regression\n",
    ")\n",
    "from imbalanced_regression_metrics import PrecisionRecallFscoreForRegression\n",
    "from boosting_learn import EnsembleTrainer\n",
    "\n",
    "load_dotenv()\n",
    "pd.set_option('display.max_rows', 800)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Word2Vec & Document Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/word2vec/test_vocab.json') as f:\n",
    "    testing_points = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_lst = os.listdir('result/word2vec/model_selections') # unsorted\n",
    "# fn_lst.remove('test_vocab.json')\n",
    "\n",
    "possible_fn = [f'w2v-epochs{e}-window{w}-init_lr{lr}.json'\n",
    "               for e in range(5, 51, 5) \n",
    "               for w in [5, 10 ,15, 20] \n",
    "               for lr in [0.025, 0.02, 0.01, 0.002]]\n",
    "\n",
    "sorted_fn = [fn for fn in possible_fn if fn in fn_lst]\n",
    "\n",
    "reg_str = r'w2v-epochs(?P<epochs>\\d+)-window(?P<window>\\d+)-init_lr(?P<lr>\\d\\.\\d+)\\.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorted_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in range(10):\n",
    "    with sns.axes_style('darkgrid'):\n",
    "        fig, axes = plt.subplots(4, 4, figsize=(20, 20), dpi=200)\n",
    "        epoch = (batch + 1) * 5\n",
    "        for i, fn in enumerate(sorted_fn[batch * 16: (batch * 16) + 16]):\n",
    "            ax = axes[i // 4, i % 4]\n",
    "            hyper_param = re.match(reg_str, fn).groupdict()\n",
    "            wv_df = pd.read_json(f'result/word2vec/model_selections/{fn}', orient='index')        \n",
    "        \n",
    "            marksize = 5\n",
    "            sns.scatterplot(\n",
    "                data=wv_df.loc[~wv_df.label.isin(testing_points['positive'])],\n",
    "                x='x',\n",
    "                y='y',\n",
    "                alpha=0.5,\n",
    "                linewidth=0.2,\n",
    "                s=marksize,\n",
    "                ax=ax\n",
    "            )\n",
    "            sns.scatterplot(\n",
    "                data=wv_df.loc[wv_df.label.isin(testing_points['positive'])],\n",
    "                x='x',\n",
    "                y='y',\n",
    "                linewidth=0.2,\n",
    "                s=20,\n",
    "                color='red',\n",
    "                ax=ax\n",
    "            )\n",
    "            ax.set_title(' | '.join([f'{k}: {v}' for k, v in hyper_param.items()]))\n",
    "            ax.set_xlim(-100, 100)\n",
    "            ax.set_ylim(-100, 100)\n",
    "            \n",
    "        fig.tight_layout()\n",
    "#         fig.savefig(f'result/img/w2v_2d_epochs{epoch}.png', dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handpick_fn_dct = [\n",
    "    (5, 20, 0.025),\n",
    "    (5, 5, 0.002),\n",
    "    (10, 5, 0.002),\n",
    "    (15, 20, 0.02),\n",
    "    (20, 20, 0.02),\n",
    "    (25, 5, 0.002),\n",
    "    (30, 10, 0.025),\n",
    "    (50, 5, 0.01)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15), dpi=200)\n",
    "    for i, (e, w, lr) in enumerate(handpick_fn_dct):\n",
    "        ax = axes[i // 3, i % 3]\n",
    "        wv_df = pd.read_json(f'result/word2vec/model_selections/w2v-epochs{e}-window{w}-init_lr{lr}.json', orient='index')\n",
    "        \n",
    "        marksize = 5\n",
    "#         sns.scatterplot(\n",
    "#             data=wv_df.loc[~wv_df.label.isin(testing_points['positive'])],\n",
    "#             x='x',\n",
    "#             y='y',\n",
    "#             alpha=0.5,\n",
    "#             linewidth=0.2,\n",
    "#             s=marksize,\n",
    "#             ax=ax\n",
    "#         )\n",
    "        sns.scatterplot(\n",
    "            data=wv_df.loc[wv_df.label.isin(testing_points['positive'])],\n",
    "            x='x',\n",
    "            y='y',\n",
    "            linewidth=0.2,\n",
    "            s=20,\n",
    "            color='red',\n",
    "            ax=ax\n",
    "        )\n",
    "#         for idx, label, x, y in wv_df.loc[wv_df.label.isin(testing_points['positive'])].itertuples():\n",
    "#             ax.text(\n",
    "#                 x=x,\n",
    "#                 y=y,\n",
    "#                 s=label,\n",
    "#                 ha='right'\n",
    "#             )\n",
    "            \n",
    "        ax.set_title(f'epochs: {e} | window: {w} | lr: {lr}')\n",
    "        ax.set_xlim(-100, 100)\n",
    "        ax.set_ylim(-100, 100)\n",
    "\n",
    "    fig.tight_layout()\n",
    "#     fig.savefig('result/img/w2v_2d_hp0.png', dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    fig = plt.figure(figsize=(8, 8), dpi=200)\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    wv_df = pd.read_json(f'result/word2vec/model_selections/w2v-epochs10-window5-init_lr0.002.json', orient='index')\n",
    "    data = wv_df.loc[wv_df.label.isin(testing_points['positive'])]\n",
    "#     data = data.loc[(data.x >= 20) & (data.x <= 60) & (data.y >= 20) & (data.y <= 60)]\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='x',\n",
    "        y='y',\n",
    "        linewidth=0.5,\n",
    "        s=30,\n",
    "        color='red',\n",
    "        alpha=0.75,\n",
    "        label='technology keyword',\n",
    "        ax=ax\n",
    "    )\n",
    "    for idx, label, x, y in data.itertuples():\n",
    "        ax.text(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            s=label,\n",
    "            ha='right'\n",
    "        )\n",
    "\n",
    "    ax.set_title('Decomposed Word2Vec keyworded vector')\n",
    "#     ax.set_xlim(15, 65)\n",
    "#     ax.set_ylim(15, 65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    fig = plt.figure(figsize=(8, 8), dpi=200)\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    wv_df = pd.read_json(f'result/word2vec/model_selections/w2v-epochs10-window5-init_lr0.002.json', orient='index')\n",
    "    data = wv_df.loc[wv_df.label.isin(testing_points['positive'])]\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=wv_df.loc[~wv_df.label.isin(testing_points['positive'])],\n",
    "        x='x',\n",
    "        y='y',\n",
    "        linewidth=0.1,\n",
    "        s=15,\n",
    "        alpha=0.6,\n",
    "        label='other vocab',\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        data=data,\n",
    "        x='x',\n",
    "        y='y',\n",
    "        linewidth=0.5,\n",
    "        s=30,\n",
    "        color='red',\n",
    "        alpha=0.75,\n",
    "        label='technology keyword',\n",
    "        ax=ax\n",
    "    )\n",
    "#     for idx, label, x, y in data.itertuples():\n",
    "#         ax.text(\n",
    "#             x=x,\n",
    "#             y=y,\n",
    "#             s=label,\n",
    "#             ha='right'\n",
    "#         )\n",
    "\n",
    "#     ax.set_title('Decomposed Word2Vec keyworded vector')\n",
    "#     ax.set_xlim(20, 40)\n",
    "#     ax.set_ylim(0, 20)\n",
    "    fig.savefig('result/img/word2vec_2d.png', dpi='figure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showcase the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tc = TopCoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cha_info = tc.get_filtered_challenge_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = tc.get_meta_data_features(encoded_tech=True, softmax_tech=True, return_df=True).join(cha_info.reindex(['total_prize', 'avg_score', 'number_of_registration', 'sub_reg_ratio'], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_targets = cha_info.reindex(['avg_score', 'number_of_registration', 'sub_reg_ratio'], axis=1)\n",
    "new_targets.sample(n=5)#.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(6, 4), dpi=200, sharey=True)\n",
    "    \n",
    "    avg_score_vc = new_targets['avg_score'].value_counts()\n",
    "    num_of_reg_vc = new_targets['number_of_registration'].value_counts()\n",
    "    sub_reg_vc = new_targets['sub_reg_ratio'].value_counts()\n",
    "    \n",
    "    sns.barplot(\n",
    "        x=['>= 90', 'the rest'],\n",
    "        y=[avg_score_vc[avg_score_vc.index >= 90].sum(), avg_score_vc[avg_score_vc.index < 90].sum()],\n",
    "        ax=axes[0]\n",
    "    )\n",
    "    axes[0].set_title('avg_score')\n",
    "    axes[0].set_ylabel('count')\n",
    "    \n",
    "    sns.barplot(\n",
    "        x=['<= 30', 'the rest'],\n",
    "        y=[num_of_reg_vc[num_of_reg_vc.index <= 30].sum(), num_of_reg_vc[num_of_reg_vc.index > 30].sum()],\n",
    "        ax=axes[1]\n",
    "    )\n",
    "    axes[1].set_title('number_of_registration')\n",
    "#     axes[1].set_ylabel('count')\n",
    "\n",
    "    sns.barplot(\n",
    "        x=['<= 0.25', 'the rest'],\n",
    "        y=[sub_reg_vc[sub_reg_vc.index <= 0.25].sum(), sub_reg_vc[sub_reg_vc.index > 0.25].sum()],\n",
    "        ax=axes[2]\n",
    "    )\n",
    "    axes[2].set_title('sub_reg_ratio')\n",
    "#     axes[2].set_ylabel('count')\n",
    "    \n",
    "    \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalance metrics for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = tc.get_meta_data_features(encoded_tech=True, softmax_tech=True, return_df=True).join(cha_info.reindex(['total_prize'], axis=1))\n",
    "num_of_reg = cha_info['number_of_registration']\n",
    "avg_score = cha_info['avg_score']\n",
    "sub_reg_ratio = cha_info['sub_reg_ratio']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sns.axes_style('whitegrid'):\n",
    "    fig = plt.figure(figsize=(16, 3), dpi=200)\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    sns.boxplot(x=avg_score, ax=ax)\n",
    "    ax.set_xticks(list(range(10, 110, 10)))\n",
    "    \n",
    "with sns.axes_style('whitegrid'):\n",
    "    fig = plt.figure(figsize=(16, 3), dpi=200)\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    sns.boxplot(x=num_of_reg, ax=ax)\n",
    "    ax.set_xticks(list(range(0, 310, 10)))\n",
    "    \n",
    "with sns.axes_style('whitegrid'):\n",
    "    fig = plt.figure(figsize=(16, 3), dpi=200)\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    sns.boxplot(x=sub_reg_ratio, ax=ax)\n",
    "    ax.set_xticks(np.linspace(0, 10, 11) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_vcount = avg_score.value_counts().sort_index(ascending=False)\n",
    "nr_vcount = num_of_reg.value_counts().sort_index()\n",
    "sr_vcount = sub_reg_ratio.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "as_vcount_agg = pd.Series(\n",
    "    [\n",
    "        as_vcount[as_vcount.index >= 90].sum(), \n",
    "        *[as_vcount[(as_vcount.index < h) & (as_vcount.index >= l)].sum() for h, l in zip(range(90, 0, -10), range(80, -1, -10))]\n",
    "    ],\n",
    "    index=['>= 90', *[f'[{i + 9}, {i}' for i in range(80, -1, -10)]]\n",
    ")\n",
    "\n",
    "nr_vcount_agg = pd.Series([\n",
    "    nr_vcount[nr_vcount.index <= 30].sum(),\n",
    "    *[nr_vcount[(nr_vcount.index >= l) & (nr_vcount.index <= h)].sum() for l, h in zip(range(31, 142, 10), range(40, 151, 10))],\n",
    "    nr_vcount[nr_vcount.index > 150].sum()\n",
    "], index=['<= 30', *[f'[{i - 9}, {i}]' for i in range(40, 151, 10)], '> 150'])\n",
    "\n",
    "sr_vcount_agg = pd.Series([\n",
    "    sr_vcount[sr_vcount.index <= 0.25].sum(),\n",
    "    *[sr_vcount[(sr_vcount.index > (l / 100)) & (sr_vcount.index <= h / 100)].sum() for l, h in zip(range(25, 100, 5), range(30, 101, 5))]\n",
    "], index=['<= 0.25', *[f'({(i - 5) / 100}, {i / 100}]' for i in range(30, 101, 5)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_vcount.sum(), sr_vcount_agg.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    fig = plt.figure(figsize=(10, 3), dpi=200)\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    sns.barplot(x=as_vcount_agg.index, y=as_vcount_agg, ax=ax)\n",
    "\n",
    "    for p in ax.patches:\n",
    "        text = int(p.get_height())\n",
    "        x = p.get_x() + 0.5 * p.get_width()\n",
    "        y = p.get_height() + 0.3\n",
    "        ax.text(x, y, text, ha='center')\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    fig = plt.figure(figsize=(10, 3), dpi=200)\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    sns.barplot(x=nr_vcount_agg.index, y=nr_vcount_agg, ax=ax)\n",
    "\n",
    "    for p in ax.patches:\n",
    "        text = int(p.get_height())\n",
    "        x = p.get_x() + 0.5 * p.get_width()\n",
    "        y = p.get_height() + 0.3\n",
    "        ax.text(x, y, text, ha='center')\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    fig = plt.figure(figsize=(10, 3), dpi=200)\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    sns.barplot(x=sr_vcount_agg.index, y=sr_vcount_agg, ax=ax)\n",
    "\n",
    "    for p in ax.patches:\n",
    "        text = int(p.get_height())\n",
    "        x = p.get_x() + 0.5 * p.get_width()\n",
    "        y = p.get_height() + 0.3\n",
    "        ax.text(x, y, text, ha='center')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf_score = PrecisionRecallFscoreForRegression(\n",
    "    tE=0.6,\n",
    "    tL=3,\n",
    "    c=90,\n",
    "    extreme='low',\n",
    "    decay=0.1,\n",
    "    delta=1e-4\n",
    ")\n",
    "prf_score.phi(91), prf_score.phi(90), prf_score.phi(89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(16, 7), dpi=200)\n",
    "    \n",
    "    sns.scatterplot(x=avg_score.to_numpy(), y=prf_score.phi(avg_score.to_numpy()), ax=axes[0], s=12)\n",
    "    axes[0].axhline(0.6, color='red', alpha=0.75, linewidth=0.5)\n",
    "    sns.boxplot(x=avg_score, ax=axes[1])\n",
    "    axes[1].set_xticks(list(range(10, 110, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf_reg = PrecisionRecallFscoreForRegression(\n",
    "    tE=0.6,\n",
    "    tL=8,\n",
    "    c=30,\n",
    "    extreme='high',\n",
    "    decay=0.5\n",
    ")\n",
    "prf_reg.phi(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(16, 7), dpi=200)\n",
    "    \n",
    "    sns.scatterplot(x=num_of_reg.to_numpy(), y=prf_reg.phi(num_of_reg.to_numpy()), ax=axes[0], s=10)\n",
    "    axes[0].set_xticks(list(range(0, 360, 10)))\n",
    "    sns.boxplot(x=num_of_reg, ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prf_sub = PrecisionRecallFscoreForRegression(\n",
    "    tE=0.6,\n",
    "    tL=0.07,\n",
    "    c=0.25,\n",
    "    extreme='high'\n",
    ")\n",
    "prf_sub.phi(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(16, 7), dpi=200)\n",
    "    \n",
    "    sns.scatterplot(x=sub_reg_ratio.to_numpy(), y=prf_sub.phi(sub_reg_ratio.to_numpy()), ax=axes[0], s=10)\n",
    "#     axes[0].set_xticks(list(range(0, 360, 10)))\n",
    "    sns.boxplot(x=sub_reg_ratio, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use SOMGN/SMOTER for over-sampling\n",
    "\n",
    "Done in the `.py` files. There is a implement available in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(os.listdir('result/boosting_learn/learning_data/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection (unfinished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = os.path.join('result', 'boosting_learn', 'model_selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score_res = {}\n",
    "for reg in 'gradientboostingregressor', 'randomforestregressor':\n",
    "    for dv in 0, 1:\n",
    "        with open(os.path.join(res_path, f'avg_score_{reg}_dv{dv}.json')) as f:\n",
    "            avg_score_res[(reg, dv)] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_reg_res = {}\n",
    "for reg in 'gradientboostingregressor', 'randomforestregressor':\n",
    "    for dv in 0, 1:\n",
    "        try:\n",
    "            with open(os.path.join(res_path, f'number_of_registration_{reg}_dv{dv}_rs.json')) as f:\n",
    "                num_of_reg_res[(reg, dv)] = json.load(f)\n",
    "        except OSError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_reg_res_df = pd.DataFrame.from_dict({k: {vk: vv for vk, vv in v.items() if vk != 'best_params'} for k, v in num_of_reg_res.items()})\n",
    "num_of_reg_res_df.columns.names = ['regressor', 'dv']\n",
    "num_of_reg_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score_df = pd.DataFrame.from_dict({k: {vk: vv for vk, vv in v.items() if vk != 'best_params'} for k, v in avg_score_res.items()})\n",
    "avg_score_df.columns.names = ['regressor', 'dv']\n",
    "avg_score_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = EnsembleTrainer.read_dataset('avg_score', 'train_resample', 0)\n",
    "X_test, y_test = EnsembleTrainer.read_dataset('avg_score', 'test', 0)\n",
    "\n",
    "prf_score = PrecisionRecallFscoreForRegression(tE=0.6, tL=3, c=90, extreme='low', decay=0.1)\n",
    "\n",
    "rfreg = RandomForestRegressor(**avg_score_res[('randomforestregressor', 1)]['best_params'], n_jobs=-1)\n",
    "rfreg.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = rfreg.predict(X_train)\n",
    "y_pred = rfreg.predict(X_test)\n",
    "\n",
    "print(f'r2 score: {rfreg.score(X_test, y_test)}')\n",
    "print(f'train mae: {mean_absolute_error(y_train, y_train_pred)}\\ntest mae: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'train mse: {mean_squared_error(y_train, y_train_pred)}\\ntest mse: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'regression precision:\\n\\ttrain: {prf_score.precision(y_train, y_train_pred)}\\n\\ttest: {prf_score.precision(y_test, y_pred)}')\n",
    "print(f'regression recal:\\n\\ttrain: {prf_score.recall(y_train, y_train_pred)}\\n\\ttest: {prf_score.recall(y_test, y_pred)}')\n",
    "print(f'regression precision:\\n\\ttrain: {prf_score.fscore(y_train, y_train_pred)}\\n\\ttest: {prf_score.fscore(y_test, y_pred)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = EnsembleTrainer.read_dataset('avg_score', 'train_resample', 1)\n",
    "X_test, y_test = EnsembleTrainer.read_dataset('avg_score', 'test', 1)\n",
    "\n",
    "prf_score = PrecisionRecallFscoreForRegression(tE=0.6, tL=3, c=90, extreme='low', decay=0.1)\n",
    "\n",
    "rfreg = RandomForestRegressor(**avg_score_res[('randomforestregressor', 1)]['best_params'], n_jobs=-1)\n",
    "rfreg.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = rfreg.predict(X_train)\n",
    "y_pred = rfreg.predict(X_test)\n",
    "\n",
    "print(f'r2 score: {rfreg.score(X_test, y_test)}')\n",
    "print(f'train mae: {mean_absolute_error(y_train, y_train_pred)}\\ntest mae: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'train mse: {mean_squared_error(y_train, y_train_pred)}\\ntest mse: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'regression precision:\\n\\ttrain: {prf_score.precision(y_train, y_train_pred)}\\n\\ttest: {prf_score.precision(y_test, y_pred)}')\n",
    "print(f'regression recal:\\n\\ttrain: {prf_score.recall(y_train, y_train_pred)}\\n\\ttest: {prf_score.recall(y_test, y_pred)}')\n",
    "print(f'regression precision:\\n\\ttrain: {prf_score.fscore(y_train, y_train_pred)}\\n\\ttest: {prf_score.fscore(y_test, y_pred)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = EnsembleTrainer.read_dataset('avg_score', 'train_resample', 0)\n",
    "X_test, y_test = EnsembleTrainer.read_dataset('avg_score', 'test', 0)\n",
    "\n",
    "rfreg = RandomForestRegressor(**avg_score_res[('randomforestregressor', 1)]['best_params'], n_jobs=-1)\n",
    "train_sizes, train_score, test_score = learning_curve(\n",
    "    rfreg,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    train_sizes=np.linspace(0.1, 1, 10),\n",
    "    verbose=1,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    fig = plt.figure(figsize=(8, 3), dpi=200)\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    for i, score in enumerate((train_score, test_score)):\n",
    "        mean = np.mean(score, axis=1)\n",
    "        std = np.std(score, axis=1)\n",
    "        \n",
    "        sns.lineplot(\n",
    "            x=train_sizes,\n",
    "            y=mean,\n",
    "            label='val_score' if i else 'train_score',\n",
    "            marker='o',\n",
    "            markersize=5,\n",
    "            ax=ax,\n",
    "        )\n",
    "        \n",
    "    ax.set_xticks(train_sizes)\n",
    "    ax.set_ylim(-0.5, 1.2)\n",
    "#     ax.set_yticks([i / 10 for i in range(10)] + [1])\n",
    "        \n",
    "    fig.savefig('temp_fig_lrcurve_avg_score_dv0.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = EnsembleTrainer.read_dataset('avg_score', 'train_resample', 0)\n",
    "X_test, y_test = EnsembleTrainer.read_dataset('avg_score', 'test', 0)\n",
    "\n",
    "prf_score = PrecisionRecallFscoreForRegression(tE=0.6, tL=3, c=90, extreme='low', decay=0.1)\n",
    "\n",
    "c = GradientBoostingRegressor(**avg_score_res[('gradientboostingregressor', 1)]['best_params'])\n",
    "gbreg.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = gbreg.predict(X_train)\n",
    "y_pred = gbreg.predict(X_test)\n",
    "\n",
    "print(f'r2 score: {gbreg.score(X_test, y_test)}')\n",
    "print(f'train mae: {mean_absolute_error(y_train, y_train_pred)}\\ntest mae: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'train mse: {mean_squared_error(y_train, y_train_pred)}\\ntest mse: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'regression precision:\\n\\ttrain: {prf_score.precision(y_train, y_train_pred)}\\n\\ttest: {prf_score.precision(y_test, y_pred)}')\n",
    "print(f'regression recal:\\n\\ttrain: {prf_score.recall(y_train, y_train_pred)}\\n\\ttest: {prf_score.recall(y_test, y_pred)}')\n",
    "print(f'regression precision:\\n\\ttrain: {prf_score.fscore(y_train, y_train_pred)}\\n\\ttest: {prf_score.fscore(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbreg = GradientBoostingRegressor(**avg_score_res[('gradientboostingregressor', 1)]['best_params'])\n",
    "train_sizes_gbr, train_score_gbr, test_score_gbr = learning_curve(\n",
    "    gbreg,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    train_sizes=np.linspace(0.1, 1, 10),\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    fig = plt.figure(figsize=(8, 3), dpi=200)\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    for i, score in enumerate((train_score_gbr, test_score_gbr)):\n",
    "        mean = np.mean(score, axis=1)\n",
    "        std = np.std(score, axis=1)\n",
    "        \n",
    "        sns.lineplot(\n",
    "            x=train_sizes_gbr,\n",
    "            y=mean,\n",
    "            label='val_score' if i else 'train_score',\n",
    "            marker='o',\n",
    "            markersize=4,\n",
    "            ax=ax,\n",
    "        )\n",
    "        \n",
    "    ax.set_xticks(train_sizes_gbr)\n",
    "    ax.set_ylim(-0.75, 1.2)\n",
    "        \n",
    "    fig.savefig('temp_fig_avg_score_gbg_dv0.png', dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score_res[('gradientboostingregressor', 1)]['best_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = datetime.now()\n",
    "tc = TopCoder()\n",
    "e = datetime.now()\n",
    "\n",
    "print(e - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing run for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mre(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred) / y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = tc.build_final_dataset('number_of_registration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbreg = GradientBoostingRegressor(\n",
    "    n_estimators=2000,\n",
    "    loss='ls',\n",
    "#     learning_rate=0.05,\n",
    "    n_iter_no_change=5,\n",
    "    tol=0.01,\n",
    "    validation_fraction=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "# gbreg = LinearRegression()\n",
    "\n",
    "gbreg.fit(X_train_std, y_train.to_numpy())\n",
    "y_pred = gbreg.predict(X_test_std)\n",
    "y_train_pred = gbreg.predict(X_train_std)\n",
    "\n",
    "print(f'===== 2000 | ls =====')\n",
    "# print(f'Actuall estimator: {gbreg.n_estimators_}')\n",
    "print(f'TEST\\t score: {gbreg.score(X_test_std, y_test.to_numpy())}')\n",
    "print(f'Train\\t score: {gbreg.score(X_train_std, y_train.to_numpy())}')\n",
    "print(f'TEST\\tmae: {mean_absolute_error(y_test.to_numpy(), y_pred)} | mse: {mean_squared_error(y_test.to_numpy(), y_pred)} | mre: {mre(y_test.to_numpy(), y_pred)}')\n",
    "print(f'TRAIN\\tmae: {mean_absolute_error(y_train.to_numpy(), y_train_pred)} | mse: {mean_squared_error(y_train.to_numpy(), y_train_pred)} | mre: {mre(y_train.to_numpy(), y_train_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdreg = RandomForestRegressor(\n",
    "    n_estimators=2000,\n",
    "#     max_features=X_train.shape[1] // 3,\n",
    "    min_samples_leaf=5,\n",
    "    min_impurity_decrease=0.5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "rdreg.fit(X_train_std, y_train.to_numpy())\n",
    "y_pred = rdreg.predict(X_test_std)\n",
    "y_train_pred = rdreg.predict(X_train_std)\n",
    "\n",
    "print(f'===== RESULT | mid =====')\n",
    "print(f'Actuall estimator: {rdreg.n_estimators}')\n",
    "print(f'TEST\\tscore: {rdreg.score(X_test_std, y_test.to_numpy())}')\n",
    "print(f'Train\\tscore: {rdreg.score(X_train_std, y_train.to_numpy())}')\n",
    "print(f'TEST\\tmae: {mean_absolute_error(y_test.to_numpy(), y_pred)} | mse: {mean_squared_error(y_test.to_numpy(), y_pred)}')\n",
    "print(f'TRAIN\\tmae: {mean_absolute_error(y_train.to_numpy(), y_train_pred)} | mse: {mean_squared_error(y_train.to_numpy(), y_train_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adreg = AdaBoostRegressor(\n",
    "    base_estimator=DecisionTreeRegressor(max_depth=3),\n",
    "    loss='square',\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adreg.fit(X_train_std, y_train.to_numpy())\n",
    "y_pred = adreg.predict(X_test_std)\n",
    "y_train_pred = adreg.predict(X_train_std)\n",
    "\n",
    "print(f'===== RESULT =====')\n",
    "#     print(f'Actuall estimator: {adreg.n_estimators}')\n",
    "print(f'TEST\\tscore: {adreg.score(X_test_std, y_test.to_numpy())}')\n",
    "print(f'Train\\t score: {adreg.score(X_train_std, y_train.to_numpy())}')\n",
    "print(f'TEST\\tmae: {mean_absolute_error(y_test.to_numpy(), y_pred)} | mse: {mean_squared_error(y_test.to_numpy(), y_pred)}')\n",
    "print(f'TRAIN\\tmae: {mean_absolute_error(y_train.to_numpy(), y_train_pred)} | mse: {mean_squared_error(y_train.to_numpy(), y_train_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (BERT TCPM)",
   "language": "python",
   "name": "bert_tcpm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
